{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: gradio==4.44.0 in /home/HwHiAiUser/.local/lib/python3.9/site-packages (4.44.0)\n",
      "Requirement already satisfied: ffmpy in /home/HwHiAiUser/.local/lib/python3.9/site-packages (from gradio==4.44.0) (0.4.0)\n",
      "Requirement already satisfied: python-multipart>=0.0.9 in /home/HwHiAiUser/.local/lib/python3.9/site-packages (from gradio==4.44.0) (0.0.12)\n",
      "Requirement already satisfied: anyio<5.0,>=3.0 in /usr/local/miniconda3/lib/python3.9/site-packages (from gradio==4.44.0) (4.2.0)\n",
      "Requirement already satisfied: jinja2<4.0 in /usr/local/miniconda3/lib/python3.9/site-packages (from gradio==4.44.0) (3.1.3)\n",
      "Requirement already satisfied: pandas<3.0,>=1.0 in /home/HwHiAiUser/.local/lib/python3.9/site-packages (from gradio==4.44.0) (2.2.3)\n",
      "Requirement already satisfied: pydub in /home/HwHiAiUser/.local/lib/python3.9/site-packages (from gradio==4.44.0) (0.25.1)\n",
      "Requirement already satisfied: typer<1.0,>=0.12 in /home/HwHiAiUser/.local/lib/python3.9/site-packages (from gradio==4.44.0) (0.12.5)\n",
      "Requirement already satisfied: packaging in /usr/local/miniconda3/lib/python3.9/site-packages (from gradio==4.44.0) (23.1)\n",
      "Requirement already satisfied: tomlkit==0.12.0 in /home/HwHiAiUser/.local/lib/python3.9/site-packages (from gradio==4.44.0) (0.12.0)\n",
      "Requirement already satisfied: semantic-version~=2.0 in /home/HwHiAiUser/.local/lib/python3.9/site-packages (from gradio==4.44.0) (2.10.0)\n",
      "Requirement already satisfied: huggingface-hub>=0.19.3 in /home/HwHiAiUser/.local/lib/python3.9/site-packages (from gradio==4.44.0) (0.25.2)\n",
      "Requirement already satisfied: importlib-resources<7.0,>=1.3 in /usr/local/miniconda3/lib/python3.9/site-packages (from gradio==4.44.0) (6.1.1)\n",
      "Requirement already satisfied: urllib3~=2.0 in /home/HwHiAiUser/.local/lib/python3.9/site-packages (from gradio==4.44.0) (2.2.3)\n",
      "Requirement already satisfied: ruff>=0.2.2 in /home/HwHiAiUser/.local/lib/python3.9/site-packages (from gradio==4.44.0) (0.6.9)\n",
      "Requirement already satisfied: orjson~=3.0 in /home/HwHiAiUser/.local/lib/python3.9/site-packages (from gradio==4.44.0) (3.10.7)\n",
      "Requirement already satisfied: gradio-client==1.3.0 in /home/HwHiAiUser/.local/lib/python3.9/site-packages (from gradio==4.44.0) (1.3.0)\n",
      "Requirement already satisfied: fastapi<1.0 in /home/HwHiAiUser/.local/lib/python3.9/site-packages (from gradio==4.44.0) (0.115.2)\n",
      "Requirement already satisfied: pyyaml<7.0,>=5.0 in /usr/local/miniconda3/lib/python3.9/site-packages (from gradio==4.44.0) (6.0.1)\n",
      "Requirement already satisfied: numpy<3.0,>=1.0 in /usr/local/miniconda3/lib/python3.9/site-packages (from gradio==4.44.0) (1.22.4)\n",
      "Requirement already satisfied: matplotlib~=3.0 in /usr/local/miniconda3/lib/python3.9/site-packages (from gradio==4.44.0) (3.8.2)\n",
      "Requirement already satisfied: typing-extensions~=4.0 in /usr/local/miniconda3/lib/python3.9/site-packages (from gradio==4.44.0) (4.9.0)\n",
      "Requirement already satisfied: pydantic>=2.0 in /usr/local/miniconda3/lib/python3.9/site-packages (from gradio==4.44.0) (2.5.3)\n",
      "Requirement already satisfied: uvicorn>=0.14.0 in /home/HwHiAiUser/.local/lib/python3.9/site-packages (from gradio==4.44.0) (0.32.0)\n",
      "Requirement already satisfied: httpx>=0.24.1 in /home/HwHiAiUser/.local/lib/python3.9/site-packages (from gradio==4.44.0) (0.27.2)\n",
      "Requirement already satisfied: pillow<11.0,>=8.0 in /usr/local/miniconda3/lib/python3.9/site-packages (from gradio==4.44.0) (10.2.0)\n",
      "Requirement already satisfied: aiofiles<24.0,>=22.0 in /home/HwHiAiUser/.local/lib/python3.9/site-packages (from gradio==4.44.0) (23.2.1)\n",
      "Requirement already satisfied: markupsafe~=2.0 in /usr/local/miniconda3/lib/python3.9/site-packages (from gradio==4.44.0) (2.1.4)\n",
      "Requirement already satisfied: fsspec in /usr/local/miniconda3/lib/python3.9/site-packages (from gradio-client==1.3.0->gradio==4.44.0) (2023.12.2)\n",
      "Requirement already satisfied: websockets<13.0,>=10.0 in /home/HwHiAiUser/.local/lib/python3.9/site-packages (from gradio-client==1.3.0->gradio==4.44.0) (12.0)\n",
      "Requirement already satisfied: idna>=2.8 in /usr/local/miniconda3/lib/python3.9/site-packages (from anyio<5.0,>=3.0->gradio==4.44.0) (3.4)\n",
      "Requirement already satisfied: sniffio>=1.1 in /usr/local/miniconda3/lib/python3.9/site-packages (from anyio<5.0,>=3.0->gradio==4.44.0) (1.3.0)\n",
      "Requirement already satisfied: exceptiongroup>=1.0.2 in /usr/local/miniconda3/lib/python3.9/site-packages (from anyio<5.0,>=3.0->gradio==4.44.0) (1.2.0)\n",
      "Requirement already satisfied: starlette<0.41.0,>=0.37.2 in /home/HwHiAiUser/.local/lib/python3.9/site-packages (from fastapi<1.0->gradio==4.44.0) (0.40.0)\n",
      "Requirement already satisfied: certifi in /usr/local/miniconda3/lib/python3.9/site-packages (from httpx>=0.24.1->gradio==4.44.0) (2023.11.17)\n",
      "Requirement already satisfied: httpcore==1.* in /home/HwHiAiUser/.local/lib/python3.9/site-packages (from httpx>=0.24.1->gradio==4.44.0) (1.0.6)\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in /home/HwHiAiUser/.local/lib/python3.9/site-packages (from httpcore==1.*->httpx>=0.24.1->gradio==4.44.0) (0.14.0)\n",
      "Requirement already satisfied: filelock in /usr/local/miniconda3/lib/python3.9/site-packages (from huggingface-hub>=0.19.3->gradio==4.44.0) (3.13.1)\n",
      "Requirement already satisfied: requests in /home/HwHiAiUser/.local/lib/python3.9/site-packages (from huggingface-hub>=0.19.3->gradio==4.44.0) (2.32.3)\n",
      "Requirement already satisfied: tqdm>=4.42.1 in /home/HwHiAiUser/.local/lib/python3.9/site-packages (from huggingface-hub>=0.19.3->gradio==4.44.0) (4.66.5)\n",
      "Requirement already satisfied: zipp>=3.1.0 in /usr/local/miniconda3/lib/python3.9/site-packages (from importlib-resources<7.0,>=1.3->gradio==4.44.0) (3.17.0)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/miniconda3/lib/python3.9/site-packages (from matplotlib~=3.0->gradio==4.44.0) (4.47.2)\n",
      "Requirement already satisfied: cycler>=0.10 in /usr/local/miniconda3/lib/python3.9/site-packages (from matplotlib~=3.0->gradio==4.44.0) (0.12.1)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/miniconda3/lib/python3.9/site-packages (from matplotlib~=3.0->gradio==4.44.0) (3.1.1)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/miniconda3/lib/python3.9/site-packages (from matplotlib~=3.0->gradio==4.44.0) (1.4.5)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/miniconda3/lib/python3.9/site-packages (from matplotlib~=3.0->gradio==4.44.0) (2.8.2)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/miniconda3/lib/python3.9/site-packages (from matplotlib~=3.0->gradio==4.44.0) (1.2.0)\n",
      "Requirement already satisfied: pytz>=2020.1 in /usr/local/miniconda3/lib/python3.9/site-packages (from pandas<3.0,>=1.0->gradio==4.44.0) (2023.3.post1)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /home/HwHiAiUser/.local/lib/python3.9/site-packages (from pandas<3.0,>=1.0->gradio==4.44.0) (2024.2)\n",
      "Requirement already satisfied: pydantic-core==2.14.6 in /usr/local/miniconda3/lib/python3.9/site-packages (from pydantic>=2.0->gradio==4.44.0) (2.14.6)\n",
      "Requirement already satisfied: annotated-types>=0.4.0 in /usr/local/miniconda3/lib/python3.9/site-packages (from pydantic>=2.0->gradio==4.44.0) (0.6.0)\n",
      "Requirement already satisfied: rich>=10.11.0 in /home/HwHiAiUser/.local/lib/python3.9/site-packages (from typer<1.0,>=0.12->gradio==4.44.0) (13.9.2)\n",
      "Requirement already satisfied: shellingham>=1.3.0 in /home/HwHiAiUser/.local/lib/python3.9/site-packages (from typer<1.0,>=0.12->gradio==4.44.0) (1.5.4)\n",
      "Requirement already satisfied: click>=8.0.0 in /usr/local/miniconda3/lib/python3.9/site-packages (from typer<1.0,>=0.12->gradio==4.44.0) (8.1.7)\n",
      "Requirement already satisfied: six>=1.5 in /usr/local/miniconda3/lib/python3.9/site-packages (from python-dateutil>=2.7->matplotlib~=3.0->gradio==4.44.0) (1.16.0)\n",
      "Requirement already satisfied: markdown-it-py>=2.2.0 in /home/HwHiAiUser/.local/lib/python3.9/site-packages (from rich>=10.11.0->typer<1.0,>=0.12->gradio==4.44.0) (3.0.0)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/miniconda3/lib/python3.9/site-packages (from rich>=10.11.0->typer<1.0,>=0.12->gradio==4.44.0) (2.17.2)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/miniconda3/lib/python3.9/site-packages (from requests->huggingface-hub>=0.19.3->gradio==4.44.0) (2.0.4)\n",
      "Requirement already satisfied: mdurl~=0.1 in /home/HwHiAiUser/.local/lib/python3.9/site-packages (from markdown-it-py>=2.2.0->rich>=10.11.0->typer<1.0,>=0.12->gradio==4.44.0) (0.1.2)\n"
     ]
    }
   ],
   "source": [
    "#install gradio\n",
    "\n",
    "!pip install gradio==4.44.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[WARNING] ME(4916:255086446710816,MainProcess):2025-08-06-20:20:55.592.653 [mindspore/run_check/_check_version.py:324] MindSpore version 2.5.0 and Ascend AI software package (Ascend Data Center Solution)version 8.2 does not match, the version of software package expect one of ['7.5', '7.6']. Please refer to the match info on: https://www.mindspore.cn/install\n",
      "/usr/local/miniconda3/lib/python3.9/site-packages/numpy/core/getlimits.py:499: UserWarning: The value of the smallest subnormal for <class 'numpy.float64'> type is zero.\n",
      "  setattr(self, word, getattr(machar, word).flat[0])\n",
      "/usr/local/miniconda3/lib/python3.9/site-packages/numpy/core/getlimits.py:89: UserWarning: The value of the smallest subnormal for <class 'numpy.float64'> type is zero.\n",
      "  return self._float_to_str(self.smallest_subnormal)\n",
      "/usr/local/miniconda3/lib/python3.9/site-packages/numpy/core/getlimits.py:499: UserWarning: The value of the smallest subnormal for <class 'numpy.float32'> type is zero.\n",
      "  setattr(self, word, getattr(machar, word).flat[0])\n",
      "/usr/local/miniconda3/lib/python3.9/site-packages/numpy/core/getlimits.py:89: UserWarning: The value of the smallest subnormal for <class 'numpy.float32'> type is zero.\n",
      "  return self._float_to_str(self.smallest_subnormal)\n",
      "[WARNING] ME(4916:255086446710816,MainProcess):2025-08-06-20:20:59.888.419 [mindspore/run_check/_check_version.py:342] MindSpore version 2.5.0 and \"te\" wheel package version 8.2 does not match. For details, refer to the installation guidelines: https://www.mindspore.cn/install\n",
      "[WARNING] ME(4916:255086446710816,MainProcess):2025-08-06-20:20:59.893.687 [mindspore/run_check/_check_version.py:349] MindSpore version 2.5.0 and \"hccl\" wheel package version 8.2 does not match. For details, refer to the installation guidelines: https://www.mindspore.cn/install\n",
      "[WARNING] ME(4916:255086446710816,MainProcess):2025-08-06-20:20:59.900.360 [mindspore/run_check/_check_version.py:363] Please pay attention to the above warning, countdown: 3\n",
      "[WARNING] ME(4916:255086446710816,MainProcess):2025-08-06-20:21:00.904.780 [mindspore/run_check/_check_version.py:363] Please pay attention to the above warning, countdown: 2\n",
      "[WARNING] ME(4916:255086446710816,MainProcess):2025-08-06-20:21:01.907.525 [mindspore/run_check/_check_version.py:363] Please pay attention to the above warning, countdown: 1\n",
      "[WARNING] ME(4916:255086446710816,MainProcess):2025-08-06-20:21:07.292.120 [mindspore/context.py:1335] For 'context.set_context', the parameter 'ascend_config' will be deprecated and removed in a future version. Please use the api mindspore.device_context.ascend.op_precision.precision_mode(),\n",
      "                                                       mindspore.device_context.ascend.op_precision.op_precision_mode(),\n",
      "                                                       mindspore.device_context.ascend.op_precision.matmul_allow_hf32(),\n",
      "                                                       mindspore.device_context.ascend.op_precision.conv_allow_hf32(),\n",
      "                                                       mindspore.device_context.ascend.op_tuning.op_compile() instead.\n",
      "Building prefix dict from the default dictionary ...\n",
      "Dumping model to file cache /tmp/jieba.cache\n",
      "Loading model cost 2.769 seconds.\n",
      "Prefix dict has been built successfully.\n"
     ]
    }
   ],
   "source": [
    "# ────────────────── 导入相关包 ──────────────────\n",
    "import os\n",
    "import base64\n",
    "import time\n",
    "import gradio as gr\n",
    "import mindspore\n",
    "from mindspore import context\n",
    "\n",
    "from mindnlp.transformers import (\n",
    "    Qwen2VLForConditionalGeneration,\n",
    "    AutoProcessor,\n",
    ")\n",
    "from qwen_vl_utils import process_vision_info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[WARNING] ME(4916:255086446710816,MainProcess):2025-08-06-20:21:46.980.094 [mindspore/context.py:1335] For 'context.set_context', the parameter 'max_call_depth' will be deprecated and removed in a future version. Please use the api mindspore.set_recursion_limit() instead.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device target: Ascend\n"
     ]
    }
   ],
   "source": [
    "# ────────────────── MindSpore 环境 ──────────────────\n",
    "context.set_context(enable_debug_runtime=True)\n",
    "context.set_context(mode=context.GRAPH_MODE, max_call_depth=2000)\n",
    "print(\"Device target:\", mindspore.get_context(\"device_target\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The argument `trust_remote_code` is to be used with Auto classes. It has no effect here and is ignored.\n",
      "Unrecognized keys in `rope_scaling` for 'rope_type'='default': {'type', 'mrope_section'}\n",
      "Qwen2VLForConditionalGeneration has generative capabilities, as `prepare_inputs_for_generation` is explicitly overwritten. However, it doesn't directly inherit from `GenerationMixin`.`PreTrainedModel` will NOT inherit from `GenerationMixin`, and this model will lose the ability to call `generate` and other related functions.\n",
      "  - If you are the owner of the model architecture code, please modify your model class such that it inherits from `GenerationMixin` (after `PreTrainedModel`, otherwise you'll get an exception).\n",
      "  - If you are not the owner of the model architecture class, please contact the model code owner to update it.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model ... (首次可能较慢)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Qwen2VLRotaryEmbedding` can now be fully parameterized by passing the model config through the `config` argument. All other arguments will be removed\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "eb0f4c9b1d5141d8b042b48de3cc0e2d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MindSpore do not support bfloat16 dtype, we will automaticlly convert to float16\n"
     ]
    }
   ],
   "source": [
    "# ────────────────── 模型与处理器 ──────────────────\n",
    "MODEL_PATH = \"/home/HwHiAiUser/.cache/modelscope/hub/models/Qwen/Qwen2-VL-2B-Instruct\"\n",
    "FP16 = mindspore.float16\n",
    "\n",
    "print(\"Loading model ... (首次可能较慢)\")\n",
    "model = Qwen2VLForConditionalGeneration.from_pretrained(\n",
    "    MODEL_PATH,\n",
    "    ms_dtype=FP16,\n",
    "    trust_remote_code=True,\n",
    ")\n",
    "\n",
    "min_pixels = 256 * 28 * 28\n",
    "max_pixels = 1024 * 28 * 28\n",
    "processor = AutoProcessor.from_pretrained(\n",
    "    MODEL_PATH,\n",
    "    min_pixels=min_pixels,\n",
    "    max_pixels=max_pixels,\n",
    "    ms_dtype=FP16,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import io\n",
    "import os\n",
    "import time\n",
    "import json\n",
    "import base64\n",
    "import random\n",
    "\n",
    "import gradio as gr\n",
    "from PIL import Image\n",
    "from pathlib import Path\n",
    "from typing import List, Dict\n",
    "\n",
    "from mindspore import Tensor\n",
    "# ─────────── 工具函数 ───────────\n",
    "\n",
    "def pil_to_data_uri(pil_img):\n",
    "    buf = io.BytesIO()\n",
    "    pil_img.save(buf, format=\"PNG\")\n",
    "    b64 = base64.b64encode(buf.getvalue()).decode()\n",
    "    return f\"data:image/png;base64,{b64}\"\n",
    "\n",
    "def history_to_messages(hist: List[Dict]):\n",
    "    \"\"\"our state(list[dict]) → Qwen2-VL messages\"\"\"\n",
    "    msgs = []\n",
    "    for turn in hist:\n",
    "        user = {\"role\": \"user\", \"content\": []}\n",
    "        if turn[\"user_img\"]:\n",
    "            user[\"content\"].append({\"type\": \"image\", \"image\": turn[\"user_img\"]})\n",
    "        if turn[\"user_text\"].strip():\n",
    "            user[\"content\"].append({\"type\": \"text\", \"text\": turn[\"user_text\"]})\n",
    "        msgs.append(user)\n",
    "        msgs.append({\"role\": \"assistant\", \"content\": turn[\"assistant\"]})\n",
    "    return msgs\n",
    "\n",
    "def generate_reply(hist: List[Dict]):\n",
    "    msgs = history_to_messages(hist)\n",
    "    prompt = processor.apply_chat_template(\n",
    "        msgs, tokenize=False, add_generation_prompt=True\n",
    "    )\n",
    "    image_inputs, _ = process_vision_info(msgs)\n",
    "\n",
    "    inputs = processor(\n",
    "        text=[prompt], images=image_inputs,\n",
    "        padding=True, return_tensors=\"ms\"\n",
    "    )\n",
    "\n",
    "    for k in (\"input_ids\", \"attention_mask\", \"position_ids\"):\n",
    "        if k in inputs and inputs[k].dtype == mindspore.int64:\n",
    "            inputs[k] = inputs[k].astype(mindspore.int32)\n",
    "\n",
    "    outs = model.generate(**inputs, max_new_tokens=256)\n",
    "    trimmed = [o[len(i):] for i, o in zip(inputs[\"input_ids\"], outs)]\n",
    "    text = processor.batch_decode(\n",
    "        trimmed,\n",
    "        skip_special_tokens=True,\n",
    "        clean_up_tokenization_spaces=False\n",
    "    )[0].strip()\n",
    "    return text\n",
    "\n",
    "def ui_history(hist: List[Dict]):\n",
    "    \"\"\"state → Chatbot 所需 [(user, assistant), ...]\"\"\"\n",
    "    ui = []\n",
    "    for t in hist:\n",
    "        u_disp = \"\"\n",
    "        if t[\"user_img\"]:\n",
    "            img = Image.open(t[\"user_img\"])\n",
    "            u_disp += f'<img src=\"{pil_to_data_uri(img)}\" width=\"128\"/> '\n",
    "        u_disp += t[\"user_text\"]\n",
    "        ui.append((u_disp, t[\"assistant\"]))\n",
    "    return ui\n",
    "\n",
    "# ─────────── Gradio 回调 ───────────\n",
    "def chat_fn(user_text, user_img, state):\n",
    "    \"\"\"\n",
    "    Parameters\n",
    "    ----------\n",
    "    user_text : str\n",
    "    user_img  : PIL.Image | None\n",
    "    state     : list[dict]\n",
    "    Returns (generator)\n",
    "    -------\n",
    "    chatbot_history, state\n",
    "    \"\"\"\n",
    "    state = state or []\n",
    "\n",
    "    # 保存图片到本地，路径传给模型\n",
    "    img_path = None\n",
    "    if user_img is not None:\n",
    "        os.makedirs(\"tmp_uploads\", exist_ok=True)\n",
    "        img_path = f\"tmp_uploads/{int(time.time() * 1000)}.png\"\n",
    "        user_img.save(img_path)\n",
    "\n",
    "    # 添加新 turn，assistant 先留空\n",
    "    state.append({\n",
    "        \"user_text\": user_text or \"\",\n",
    "        \"user_img\": img_path,\n",
    "        \"assistant\": \"\"\n",
    "    })\n",
    "\n",
    "    # 第一次 yield：先把用户消息展示出来\n",
    "    yield ui_history(state), state\n",
    "\n",
    "    # 模型推理\n",
    "    reply = generate_reply(state)\n",
    "    state[-1][\"assistant\"] = reply\n",
    "\n",
    "    # 第二次 yield：展示完整对话\n",
    "    yield ui_history(state), state\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running on local URL:  http://0.0.0.0:7868\n",
      "\n",
      "To create a public link, set `share=True` in `launch()`.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><iframe src=\"http://localhost:7868/\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "# ─────────── Gradio 组件定义 ───────────\n",
    "textbox = gr.Textbox(lines=2, placeholder=\"请输入文字…\", label=\"问题\")\n",
    "image = gr.Image(type=\"pil\", label=\"上传图片（可选）\")\n",
    "state = gr.State([])  # 隐藏的对话上下文\n",
    "chatbot = gr.Chatbot(height=480,\n",
    "                     bubble_full_width=False,\n",
    "                     label=\"对话\")\n",
    "\n",
    "# ─────────── Gradio Interface ───────────\n",
    "demo = gr.Interface(\n",
    "    fn=chat_fn,\n",
    "    inputs=[textbox, image, state],\n",
    "    outputs=[chatbot, state],\n",
    "    title=\"Qwen2-VL MindSpore Demo\",\n",
    "    description=\"上传图片或输入文本，与 Qwen2-VL 进行多模态对话。\",\n",
    "    theme=\"soft\",\n",
    "    allow_flagging=\"never\",\n",
    "    clear_btn=\"清空\",\n",
    "    concurrency_limit=4\n",
    ")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    demo.launch(server_name=\"0.0.0.0\", server_port=7868, share=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
