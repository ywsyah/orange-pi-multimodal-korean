# ğŸ§ Orange-Pi Multimodal Korean  
## åŸºäºæ˜‡è…¾ AI çš„å¤šæ¨¡æ€éŸ©è¯­åº”ç”¨

åˆ©ç”¨ **â€œä¸‡å·Â·ä¸è·¯â€** å¼€æºå›¾æ–‡è¯­æ–™åº“ï¼Œå¯¹ **Qwen2-VL-2Bä»¥åŠQwen2.5-VL-3B** æ¨¡å‹åœ¨æœåŠ¡å™¨ç«¯è¿›è¡Œ LoRA å¾®è°ƒï¼Œå¹¶åŸºäºmindsporeã€mindnlpå’Œgradioéƒ¨ç½²äº **OrangePi AIpro**ï¼ˆ20 TOPS Ascend SoCï¼‰ã€‚é¡¹ç›®æä¾›ï¼š

1. ğŸ–¼ï¸+ğŸ“**å›¾æ–‡è”åˆé—®ç­”** å¾®è°ƒä¸éƒ¨ç½²æµç¨‹ï¼ˆåŸºäºLLamafactoryå¾®è°ƒï¼‰
2. ğŸ“šğŸ”**ä¸“ä¸šæœ¯è¯­é—®ç­”** å¾®è°ƒä¸éƒ¨ç½²æµç¨‹ï¼ˆåŸºäºåŸç”Ÿtransformer+Peftåº“å¾®è°ƒï¼‰

> é€‚ç”¨äºç«¯ä¾§ä½èµ„æºå°è¯­ç§çš„ AI åœºæ™¯ï¼Œå¹¶ä¸”å­¦ä¹ ä½¿ç”¨llamafactoryæ¡†æ¶å¾®è°ƒå’ŒåŸç”Ÿtransformer+Peftè¿›è¡Œå¾®è°ƒã€‚

---

## ğŸš€ ä¸»è¦ç‰¹æ€§

| æ¨¡å— | è¯´æ˜ |
| ---- | ---- |
| **åº•åº§æ¨¡å‹** | `Qwen2-VL-2B-Instruct` / `Qwen2.5-VL-3B-Instruct` |
| **æ•°æ®é›†** | [ä¸‡å·Â·ä¸è·¯](https://opendatalab.com/OpenDataLab/WanJuanSiLu2O)ï¼ˆéŸ©è¯­ï¼‰ |
| **è®­ç»ƒæ¡†æ¶** | LLaMA-Factory 0.9.4.dev0 /  | 
| **éƒ¨ç½²å¹³å°** | OrangePi AIproï¼ˆAscend 20 TOPSï¼Œ24 GB RAMï¼‰ |
| **å¾®è°ƒæ–¹æ³•** | LoRA + SFT |

---

## âš™ï¸ ç¯å¢ƒå‡†å¤‡

### æœåŠ¡å™¨ç«¯ï¼ˆè®­ç»ƒï¼‰

| ç¡¬ä»¶ | è§„æ ¼ |
| ---- | ---- |
| GPU  | NVIDIA A100 80 GB Ã— 1 |
| CPU  | 32 cores |
| RAM  | 224 GB |

| è½¯ä»¶ | ç‰ˆæœ¬ |
| ---- | ---- |
| OS   | Ubuntu 22.04 LTS |
| Python | 3.10 |
| PyTorch | 2.7.2 + CUDA 12.2 |
| Deepspeed | å¯é€‰ï¼ˆå¤šå¡ï¼‰ |

#### llamafactoryå®‰è£…æµç¨‹ï¼ˆå‚è€ƒå®˜æ–¹githubï¼Œè¿™é‡ŒåŠ äº†å›½å†…æºï¼‰  
    git clone https://github.com/hiyouga/LLaMA-Factory.git
    conda create -n llama_factory python=3.10
    conda activate llama_factory
    cd LLaMA-Factory
    pip install -i https://pypi.tuna.tsinghua.edu.cn/simple -e .[metrics]

---

### Edge ç«¯ï¼ˆOrangePi AIproï¼‰

    MindSpore       2.5.0
    MindNLP         0.4.1
    CANN Toolkit    8.1.RC1.beta1
    Python          3.9
    gradio          4.4.0

---

## ğŸ“š è¯´æ˜
ä»¥ä¸‹è®­ç»ƒæµç¨‹æ˜¯é’ˆå¯¹ğŸ–¼ï¸+ğŸ“**å›¾æ–‡è”åˆé—®ç­”** å¾®è°ƒä¸éƒ¨ç½²æµç¨‹ï¼ˆåŸºäºLLamafactoryå¾®è°ƒï¼‰åº”ç”¨çš„
å¯¹äºğŸ“šğŸ”**ä¸“ä¸šæœ¯è¯­é—®ç­”** å¾®è°ƒä¸éƒ¨ç½²æµç¨‹ï¼ˆåŸºäºåŸç”Ÿtransformer+Peftåº“å¾®è°ƒï¼‰å‚è€ƒæ–‡ä»¶**ko_text.ipynb**ã€‚

## ğŸ“¥ æ•°æ®é›†å‡†å¤‡ä¸å¤„ç†

#### 1. ä¸‹è½½éŸ©è¯­å›¾æ–‡æ ‡æ³¨  

      https://opendatalab.com/OpenDataLab/WanJuanSiLu2O/blob/main/raw/image/ko/ko_image_caption.jsonl

#### 2. å›¾ç‰‡æ‹‰å–ä¸ç´¢å¼•é‡å»º  

       python scripts/get_all_img.py \
           --input ko_image_caption.jsonl \
           --output ko_caption_clean.json \
           --outdir data/images/ko \
           --max-lines 20000        # å¯é€‰ï¼šé™åˆ¶ä¸‹è½½æ•°é‡(0ä»£è¡¨å…¨éƒ¨ä¸‹è½½)

#### 3. æ¸…æ´—åå›¾  

       python scripts/delete_break_img.py \
           --input_json_path ko_caption_clean.json \
           --output_json_path data/ko_sharegpt.json

#### 4. è½¬æ¢ä¸º ShareGPT æ ¼å¼  

       python scripts/convert_to_sharegpt.py \
           --input_json_path ko_caption_clean.json \
           --output_json_path data/ko_sharegpt.json

   æ ·ä¾‹  

       {
         "messages": [
           {"role": "user", "content": "<image>ê·¸ë“¤ì€ ëˆ„êµ¬ì…ë‹ˆê¹Œ?"},
           {"role": "assistant", "content": "ê·¸ë“¤ì€ ë°”ì´ì—ë¥¸ ë®Œí—¨ì˜ ì¼€ì¸ê³¼ ê³ ë ˆì¸ ì¹´ì…ë‹ˆë‹¤."},
           {"role": "user", "content": "ë¬´ì—‡ì„ í•˜ê³  ìˆìŠµë‹ˆê¹Œ?"},
           {"role": "assistant", "content": "ì¶•êµ¬ì¥ì—ì„œ ì„¸ë¦¬ë¨¸ë‹ˆ ì¤‘ì…ë‹ˆë‹¤."}
         ],
         "images": ["demo_data/1.jpg"]
       }

#### 5. è®­ç»ƒ / æµ‹è¯•æ‹†åˆ†  

      python split_data.py \
          --src ko_sharegpt.json.json \
          --train_out ko_train.json \
          --eval_out ko_eval.json \
          --n_train 30000 \
          --n_eval 6000

---

## ğŸ”§ å¾®è°ƒæµç¨‹

#### 1. ä¸‹è½½åº•åº§æ¨¡å‹  

       git lfs install
       git clone https://www.modelscope.cn/Qwen/Qwen2-VL-2B-Instruct.git models/Qwen2-VL-2B-Instruct

#### 2. æ·»åŠ æ•°æ®é›†æè¿°ï¼ˆç¼–è¾‘ `LLaMA-Factory/data/dataset_info.json`ï¼‰  

       "ko_train": {
         "path": "data/ko_train.json",
         "type": "sharegpt_multi_modal"
       },
       "ko_val": {
         "path": "data/ko_val.json",
         "type": "sharegpt_multi_modal"
       }

#### 3. å¯åŠ¨ WebUI  

       llamafactory-cli webui

#### 4. å…³é”®å‚æ•°ç¤ºä¾‹(å…·ä½“å‚æ•°å‚è€ƒtrain_paramæ–‡ä»¶å¤¹ä¸‹yamlæ–‡ä»¶) 

   | é€‰é¡¹ | å€¼ |
   | ---- | -- |
   | Model name  | Qwen2-VL-2B-Instruct |
   | Model path  | models/Qwen2-VL-2B-Instruct |
   | Finetune    | LoRA |
   | Stage       | Supervised Fine-Tuning |
   | Dataset     | ko_train |
   | Max epochs  | 3 |
   | Batch size  | 16 |
   | Save steps  | 200 |
   | lora_rank   | 64 |
   | lora_alpha  | 128ï¼ˆä¸€èˆ¬æ˜¯rankçš„ä¸¤å€ï¼‰ |
   | lora_dropout | 0.05ï¼ˆé˜²æ­¢è¿‡æ‹Ÿåˆï¼‰ |
   | Output dir  | saves/Qwen2-VL/lora/Qwen2-VL-sft-ko |

### 5. ç›‘æ§æ˜¾å­˜  

       watch -n 1 nvidia-smi

### 6. è®­ç»ƒè€—æ—¶  
   å•å¼  A100 çº¦ **10 h**ï¼›æœ€ç»ˆ loss æ›²çº¿è§ `docs/training_loss.png`ã€‚

---

## ğŸ—œï¸ åˆå¹¶ LoRA & å¯¼å‡º

åœ¨ WebUI **Expert** æ ‡ç­¾æ‰§è¡Œ  

    Model path      = models/Qwen2-VL-2B-Instruct
    Checkpoint path = saves/Qwen2-VL/lora/Qwen2-VL-sft-ko
    Export path     = models/Qwen2-VL-sft-final

ç‚¹å‡»â€œå¼€å§‹å¯¼å‡ºâ€ï¼Œå¾—åˆ°åˆå¹¶æƒé‡ã€‚

---

## ğŸ“¦ è¾¹ç¼˜ç«¯éƒ¨ç½²

1. å°† `models/Qwen2-VL-sft-final` æ‹·è´è‡³ OrangePi AIpro  
2. å‚è€ƒ `notebooks/ko.ipynb` è¿›è¡Œæ¨ç†æµ‹è¯•ï¼š  
   â€¢ å¤šæ¨¡æ€å›¾ç‰‡é—®ç­”  
   â€¢ ä¸“ä¸šæœ¯è¯­ç¿»è¯‘ / QA

---

## ğŸ“ å¼•ç”¨

    @misc{orangepi2024multimodal,
      title   = {Orange Pi Multimodal Korean},
      author  = {Your Name},
      year    = {2024},
      url     = {https://github.com/yourrepo/orange-pi-multimodal-korean}
    }

---

